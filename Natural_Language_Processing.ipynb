{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "Natural_Language_Processing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGa6Tpmyvpmh",
        "colab_type": "text"
      },
      "source": [
        
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Bc0hSVhvpmo",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwG6vDewvpmp",
        "colab_type": "code",
        "outputId": "3c9b3819-de38-44f3-f0fa-a885b5c8209b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import cdist"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXd657Wjvpmt",
        "colab_type": "text"
      },
      "source": [
        "We need to import several things from Keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba3EIin8vpmu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from tf.keras.models import Sequential  # This does not work!\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, GRU, Embedding\n",
        "from tensorflow.python.keras.optimizers import Adam\n",
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejUwEwk4vpm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import imdb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWSX7xSWvpm7",
        "colab_type": "text"
      },
      "source": [
        "Change this if you want the files saved in another directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9eF61qsvpm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imdb.data_dir = \"data/IMDB/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TtHmW-7vpm9",
        "colab_type": "text"
      },
      "source": [
        "Automatically download and extract the files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfrkeBkWvpm-",
        "colab_type": "code",
        "outputId": "61147713-6ef0-468b-9698-2040ff2f1ce9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "imdb.maybe_download_and_extract()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "- Download progress: 100.0%\n",
            "Download finished. Extracting files.\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wn8iIxx3vpnA",
        "colab_type": "text"
      },
      "source": [
        "Load the training- and test-sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPTT5EkOvpnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_text, y_train = imdb.load_data(train=True)\n",
        "x_test_text, y_test = imdb.load_data(train=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsbApavpvpnF",
        "colab_type": "code",
        "outputId": "f491d15a-0667-4637-b0ab-862d152b6ec7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Train-set size: \", len(x_train_text))\n",
        "print(\"Test-set size:  \", len(x_test_text))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train-set size:  25000\n",
            "Test-set size:   25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEmkbR8TvpnH",
        "colab_type": "text"
      },
      "source": [
        "Combine into one data-set for some uses below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAkQurKjvpnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_text = x_train_text + x_test_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jDRYyHKvpnJ",
        "colab_type": "text"
      },
      "source": [
        "Print an example from the training-set to see that the data looks correct."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8zjmlkivpnM",
        "colab_type": "code",
        "outputId": "526a6825-2e50-4f0b-d768-a739e3131a6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WxBGJK4pwrB2"
      },
      "source": [
        "## Tokenizer\n",
        "\n",
        "A neural network cannot work directly on text-strings so we must convert it somehow. There are two steps in this conversion, the first step is called the \"tokenizer\" which converts words to integers and is done on the data-set before it is input to the neural network. The second step is an integrated part of the neural network itself and is called the \"embedding\"-layer, which is described further below.\n",
        "\n",
        "We may instruct the tokenizer to only use e.g. the 10000 most popular words from the data-set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BYXcWOoMwrB1",
        "colab": {}
      },
      "source": [
        "num_words = 10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab_type": "code",
        "id": "tHCfJB4nwrBz",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=num_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e97e2c9f-fb24-40d9-ff07-99d57c827ea7",
        "id": "vKq2fhnwwrBx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "tokenizer.fit_on_texts(data_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 9.47 s, sys: 82.5 ms, total: 9.55 s\n",
            "Wall time: 9.58 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zk1Bk1wWwrBv",
        "colab": {}
      },
      "source": [
        "if num_words is None:\n",
        "    num_words = len(tokenizer.word_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J3lj9vaHwrBr",
        "colab": {}
      },
      "source": [
        "# tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1_C5Trf-wrBq"
      },
      "source": [
        "We can then use the tokenizer to convert all texts in the training-set to lists of these tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ivjCDY3jwrBn",
        "colab": {}
      },
      "source": [
        "x_train_tokens = tokenizer.texts_to_sequences(x_train_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9yRW5zEcwrBk"
      },
      "source": [
        "For example, here is a text from the training-set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ee4001f6-20b0-4a14-fe26-7f01cffb445e",
        "id": "m89S_kRGwrBd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# x_train_text[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hello. i just watched this movie earlier today for the 14th time in 3 days. i am a history teacher that has wayyyyy too much time on my hands. i need a life. i found the movie containing a striking resemblance to broke back mountain. i also found that i look a lot like jean Lafitte if he were white. also, my favorite line in the entire movie was from Mr. Petey--\"this baby can shoot a chipmunk\\'s eye from 300 yards!!\" oh, and my favorite scene in the movie was when the British were coming in, and the one drummer who was so devoted to his work, and he drummed till the death, as if that drum would end the war altogether....but it wouldn\\'t. well, thats all i would like to say about this movie. OH, one more thing..bonnie brown is an insane physco bipolar mood swinging BEEYOTCH. that is all.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SFbEM3DMwrBT"
      },
      "source": [
        "We also need to convert the texts in the test-set to tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SVStrs68wrBM",
        "colab": {}
      },
      "source": [
        "x_test_tokens = tokenizer.texts_to_sequences(x_test_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XU2Y3ycOwpVo"
      },
      "source": [
        "## Padding and Truncating Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Mxm4mKIzwpVm",
        "colab": {}
      },
      "source": [
        "num_tokens = [len(tokens) for tokens in x_train_tokens + x_test_tokens]\n",
        "num_tokens = np.array(num_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OVv1QejiwpVl"
      },
      "source": [
        "The average number of tokens in a sequence is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c6984d37-0fcd-4cfa-a553-15a970cf5baa",
        "id": "idvs6nbEwpVk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.mean(num_tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "221.27716"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ntsxTPyTwpVj"
      },
      "source": [
        "The maximum number of tokens in a sequence is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a440296a-d1da-4d6b-d5d1-28dee4afda82",
        "id": "cSX4ALu4wpVh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.max(num_tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2208"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "97bc4717-d966-421f-d2fd-c1654cf30920",
        "id": "MX7RPSiXwpVd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
        "max_tokens = int(max_tokens)\n",
        "max_tokens"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "544"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "14b50b14-c46c-4c19-b437-6c33c57a105d",
        "id": "WQQWuFa1wpVa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.sum(num_tokens < max_tokens) / len(num_tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.94528"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QcbZ3mxgwpVY",
        "colab": {}
      },
      "source": [
        "pad = 'pre'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JPllUletwpVW",
        "colab": {}
      },
      "source": [
        "x_train_pad = pad_sequences(x_train_tokens, maxlen=max_tokens,\n",
        "                            padding=pad, truncating=pad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HM2Au-ERwpVU",
        "colab": {}
      },
      "source": [
        "x_test_pad = pad_sequences(x_test_tokens, maxlen=max_tokens,\n",
        "                           padding=pad, truncating=pad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5uCvmSlxwpVT"
      },
      "source": [
        "We have now transformed the training-set into one big matrix of integers (tokens) with this shape:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2b936737-0eef-447f-e202-197c87848311",
        "id": "33x8cPzawpVP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train_pad.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 544)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "baqNwV4DwpVN"
      },
      "source": [
        "The matrix for the test-set has the same shape:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab_type": "code",
        "outputId": "1dfa34ee-a9fd-4bd1-d1a9-38423142cd7b",
        "id": "O1OkTUMuwpVG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_test_pad.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 544)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "38zIN9BYwpVD"
      },
      "source": [
        "For example, we had the following sequence of tokens above:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c0sXbtyGwpU6"
      },
      "source": [
        "This has simply been padded to create the following sequence. Note that when this is input to the Recurrent Neural Network, then it first inputs a lot of zeros. If we had padded 'post' then it would input the integer-tokens first and then a lot of zeros. This may confuse the Recurrent Neural Network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f5237087-fb0f-41ab-c24b-07908cd9dc38",
        "id": "1g9030KQwpUw",
        "colab": {}
      },
      "source": [
        "# x_train_pad[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    3,  591,  929,    7,    7,   48,   67,   10,\n",
              "        131,   11,    6,    3,  393,   19,   12,   10,   67,  103,  121,\n",
              "          2,  121,    9,    6,  406,   27,    4,    1,  342,  713, 1317,\n",
              "         90,   16,    3,   78,  174,  694, 4910,    2, 2556, 3599,    3,\n",
              "        399,  227,   31, 4033, 2628,  441,   20,   24,  288,    7,    7,\n",
              "          9,    6,  144,    5,  114,  871,  221,  922,   43,   22,   25,\n",
              "       3639, 1897,   27,  217,    1, 9206,   20, 1306,    4,  258,    5,\n",
              "        197,   48,    6,   20,    9,  631,  411,   11,   19,  405,   18,\n",
              "          8,  614,    9, 1003,  405,   43,   22,   62,  103,   11,   19,\n",
              "         27,   67,  380,   12,    9,   80,   26,   14,  152,    2, 1451,\n",
              "          3, 2997,  153,   36,  146], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7AjVvKxvpog",
        "colab_type": "text"
      },
      "source": [
        "## Tokenizer Inverse Map\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANPbvuuAvpoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx = tokenizer.word_index\n",
        "inverse_map = dict(zip(idx.values(), idx.keys()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGMjpVaYvpoj",
        "colab_type": "text"
      },
      "source": [
        "Helper-function for converting a list of tokens back to a string of words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q74L8hMLvpok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokens_to_string(tokens):\n",
        "    # Map from tokens back to words.\n",
        "    words = [inverse_map[token] for token in tokens if token != 0]\n",
        "    \n",
        "    # Concatenate all words.\n",
        "    text = \" \".join(words)\n",
        "\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nukrWPySvpol",
        "colab_type": "text"
      },
      "source": [
        "For example, this is the original text from the data-set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "WCQNdz4xvpom",
        "colab_type": "code",
        "outputId": "9e7958ae-7b74-489e-cc4b-cf7eafd158dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "x_train_text[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hello. i just watched this movie earlier today for the 14th time in 3 days. i am a history teacher that has wayyyyy too much time on my hands. i need a life. i found the movie containing a striking resemblance to broke back mountain. i also found that i look a lot like jean Lafitte if he were white. also, my favorite line in the entire movie was from Mr. Petey--\"this baby can shoot a chipmunk\\'s eye from 300 yards!!\" oh, and my favorite scene in the movie was when the British were coming in, and the one drummer who was so devoted to his work, and he drummed till the death, as if that drum would end the war altogether....but it wouldn\\'t. well, thats all i would like to say about this movie. OH, one more thing..bonnie brown is an insane physco bipolar mood swinging BEEYOTCH. that is all.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WalsDZS7vpon",
        "colab_type": "text"
      },
      "source": [
        "We can recreate this text except for punctuation and other symbols, by converting the list of tokens back to words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUwYatrTvpoo",
        "colab_type": "code",
        "outputId": "cb8e0aa2-4d37-4db8-961b-c2a12969d1ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "tokens_to_string(x_train_tokens[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"hello i just watched this movie earlier today for the time in 3 days i am a history teacher that has too much time on my hands i need a life i found the movie containing a striking resemblance to broke back mountain i also found that i look a lot like jean if he were white also my favorite line in the entire movie was from mr this baby can shoot a eye from 300 oh and my favorite scene in the movie was when the british were coming in and the one who was so devoted to his work and he till the death as if that drum would end the war altogether but it wouldn't well thats all i would like to say about this movie oh one more thing bonnie brown is an insane mood swinging that is all\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a198FotBvpoq",
        "colab_type": "text"
      },
      "source": [
        "## Create the Recurrent Neural Network\n",
        "\n",
        "We are now ready to create the Recurrent Neural Network (RNN). We will use the Keras API for this because of its simplicity. See Tutorial #03-C for a tutorial on Keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkoaF8wIvpor",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4wBnZ5xvpot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_size = 8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LX129rJSvpow",
        "colab_type": "code",
        "outputId": "3a94437c-e22e-45f9-f473-b0354ab5ce08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "model.add(Embedding(input_dim=num_words,\n",
        "                    output_dim=embedding_size,\n",
        "                    input_length=max_tokens,\n",
        "                    name='layer_embedding'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2oToKVNvpox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(GRU(units=16, return_sequences=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4PBIQShvpoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(GRU(units=8, return_sequences=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSqaMAk9vpo1",
        "colab_type": "text"
      },
      "source": [
        "This adds the third and final GRU with 4 output units. This will be followed by a dense-layer, so it should only give the final output of the GRU and not a whole sequence of outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6pdLPYLvpo2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(GRU(units=4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_nop2pIvpo5",
        "colab_type": "text"
      },
      "source": [
        "Add a fully-connected / dense layer which computes a value between 0.0 and 1.0 that will be used as the classification output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78qzEePTvpo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EK9LMlpHvpo7",
        "colab_type": "text"
      },
      "source": [
        "Use the Adam optimizer with the given learning-rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLTMZZhGvpo7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = Adam(lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9e8AyX7vpo8",
        "colab_type": "text"
      },
      "source": [
        "Compile the Keras model so it is ready for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQsoJjPkvpo9",
        "colab_type": "code",
        "outputId": "2b2ef5de-5f95-4280-9914-cc872e226ce2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9EXOpaPvpo-",
        "colab_type": "code",
        "outputId": "392c3986-d03d-42da-e7e5-bb7b17669e0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "layer_embedding (Embedding)  (None, 544, 8)            80000     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 544, 16)           1200      \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 544, 8)            600       \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 4)                 156       \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 5         \n",
            "=================================================================\n",
            "Total params: 81,961\n",
            "Trainable params: 81,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooWv0oQ9vppD",
        "colab_type": "text"
      },
      "source": [
        "## Train the Recurrent Neural Network\n",
        "\n",
        "We can now train the model. Note that we are using the data-set with the padded sequences. We use 5% of the training-set as a small validation-set, so we have a rough idea whether the model is generalizing well or if it is perhaps over-fitting to the training-set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "WEXZGRsAvppD",
        "colab_type": "code",
        "outputId": "680f5805-3c34-4eff-a5ad-0cdcdc73f219",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "%%time\n",
        "model.fit(x_train_pad, y_train,\n",
        "          validation_split=0.05, epochs=3, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 23750 samples, validate on 1250 samples\n",
            "Epoch 1/3\n",
            "23750/23750 [==============================] - 276s 12ms/sample - loss: 0.4935 - acc: 0.7408 - val_loss: 0.3399 - val_acc: 0.8760\n",
            "Epoch 2/3\n",
            "23750/23750 [==============================] - 309s 13ms/sample - loss: 0.2779 - acc: 0.8911 - val_loss: 0.2423 - val_acc: 0.9072\n",
            "Epoch 3/3\n",
            "23750/23750 [==============================] - 311s 13ms/sample - loss: 0.2023 - acc: 0.9284 - val_loss: 0.5078 - val_acc: 0.7960\n",
            "CPU times: user 26min 27s, sys: 1min 11s, total: 27min 39s\n",
            "Wall time: 14min 58s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f86c5e52080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5dULkd0vppE",
        "colab_type": "text"
      },
      "source": [
        "## Performance on Test-Set\n",
        "\n",
        "Now that the model has been trained we can calculate its classification accuracy on the test-set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8ZPATPAvppF",
        "colab_type": "code",
        "outputId": "5872c728-1502-4b9a-b898-ef46d75d989c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%%time\n",
        "result = model.evaluate(x_test_pad, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 84s 3ms/sample - loss: 0.3591 - acc: 0.8557\n",
            "CPU times: user 1min 29s, sys: 1.35 s, total: 1min 30s\n",
            "Wall time: 1min 24s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw5HmHqUvppH",
        "colab_type": "code",
        "outputId": "efb09ab2-ca57-48da-94a8-b0c6ccc31e56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Accuracy: {0:.2%}\".format(result[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 85.57%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkAhGFXbvppI",
        "colab_type": "text"
      },
      "source": [
        "## Example of Mis-Classified Text\n",
        "\n",
        "In order to show an example of mis-classified text, we first calculate the predicted sentiment for the first 1000 texts in the test-set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tojF-eRwvppJ",
        "colab_type": "code",
        "outputId": "116178c0-0949-45c2-82c1-671eb6979e6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "y_pred = model.predict(x=x_test_pad[0:1000])\n",
        "y_pred = y_pred.T[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 7.96 s, sys: 128 ms, total: 8.09 s\n",
            "Wall time: 4.29 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZvcBZlavppL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cls_pred = np.array([1.0 if p>0.5 else 0.0 for p in y_pred])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDua-Sj9vppN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cls_true = np.array(y_test[0:1000])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNaWsGTNvppO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "incorrect = np.where(cls_pred != cls_true)\n",
        "incorrect = incorrect[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4ADYTC6vppQ",
        "colab_type": "text"
      },
      "source": [
        "Of the 1000 texts used, how many were mis-classified?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJMOyyPbvppQ",
        "colab_type": "code",
        "outputId": "6e3529f6-e815-4be8-9a54-28ec57d400ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(incorrect)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5gXMCY2vppT",
        "colab_type": "text"
      },
      "source": [
        "Let us look at the first mis-classified text. We will use its index several times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPAqqMqlvppU",
        "colab_type": "code",
        "outputId": "5476dedc-ffff-4baa-eed5-48d181d568b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "idx = incorrect[0]\n",
        "idx"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf7SF107vppV",
        "colab_type": "text"
      },
      "source": [
        "The mis-classified text is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmpHnPp-vppW",
        "colab_type": "code",
        "outputId": "c0e74391-1a70-42d4-a90c-9fa2156fc67c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "text = x_test_text[idx]\n",
        "text"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The title role of this western is played by Robert Walker, Jr. He's a young gun who with partner David Carradine gets separated after doing a contract hit on a Mexican general. In eluding their pursuers Carradine and Walker become separated. Walker comes upon the camp of lawman Robert Mitchum who takes a liking to Walker and makes him a protégé and reclamation project of sorts.<br /><br />This is the first of two films Robert Mitchum did with writer/director Burt Kennedy. The second was the more humorous The Good Guys and the Bad Guys. <br /><br />Not that Young Billy Young does not have its moments of hilarity. But it is a tripartite story involving the Walker reclamation, Mitchum's hunt for the bad who killed his son and a romantic triangle involving Mitchum, Angie Dickinson, and town boss Jack Kelly.<br /><br />The film abounds with nepotism. David Carradine is John's son. Dean Martin's daughter Deana is in this, Walker is the son of Robert Walker and Jennifer Jones and Mitchum's son Chris plays Mitchum's son in some silent flashbacks.<br /><br />Robert Mitchum got his start in westerns and always looks right at home in them. Angie Dickinson essentially repeats the role she had in Rio Bravo. Walker had a brief career playing rebellious youths and doing a good job at it. I've often wondered what happened to him. He looks hauntingly like his father. Maybe he didn't want to come to such a tragic early end like his father.<br /><br />And it that wasn't enough, Mitchum fans get to hear old rumple eyes sing the title song at the beginning of the film.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThQjsQ-1vppX",
        "colab_type": "text"
      },
      "source": [
        "These are the predicted and true classes for the text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIIMGTNpvppX",
        "colab_type": "code",
        "outputId": "190bc7db-1448-4e41-f009-bbfb5c7a38b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred[idx]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1878289"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqeAY_s2vppZ",
        "colab_type": "code",
        "outputId": "64513709-8fce-423d-837b-afff7d2762bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cls_true[idx]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWkSAiZqvppb",
        "colab_type": "text"
      },
      "source": [
        "## New Data\n",
        "\n",
        "Let us try and classify new texts that we make up. Some of these are obvious, while others use negation and sarcasm to try and confuse the model into mis-classifying the text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8RF5Qjvvppb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text1 = \"This movie is fantastic! I really like it because it is so good!\"\n",
        "text2 = \"Good movie!\"\n",
        "text3 = \"Maybe I like this movie.\"\n",
        "text4 = \"Meh ...\"\n",
        "text5 = \"If I were a drunk teenager then this movie might be good.\"\n",
        "text6 = \"Bad movie!\"\n",
        "text7 = \"Not a good movie!\"\n",
        "text8 = \"This movie really sucks! Can I get my money back please?\"\n",
        "texts = [text1, text2, text3, text4, text5, text6, text7, text8]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDthOe7qvppd",
        "colab_type": "text"
      },
      "source": [
        "We first convert these texts to arrays of integer-tokens because that is needed by the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf3jzIgOvppd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens = tokenizer.texts_to_sequences(texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6KahLVxvppe",
        "colab_type": "text"
      },
      "source": [
        "To input texts with different lengths into the model, we also need to pad and truncate them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHrtAQC2vppe",
        "colab_type": "code",
        "outputId": "7f38ee88-8945-4133-ae44-1240b022c686",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokens_pad = pad_sequences(tokens, maxlen=max_tokens,\n",
        "                           padding=pad, truncating=pad)\n",
        "tokens_pad.shape"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 544)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ky-4hA3Vvpph",
        "colab_type": "text"
      },
      "source": [
        "We can now use the trained model to predict the sentiment for these texts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPqLaRL8vppi",
        "colab_type": "code",
        "outputId": "af2c9e9a-ef6a-4ba7-b9bb-e3dd30b10567",
        "colab": {}
      },
      "source": [
        "model.predict(tokens_pad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.868934  ],\n",
              "       [0.72526425],\n",
              "       [0.33099633],\n",
              "       [0.49190348],\n",
              "       [0.3054021 ],\n",
              "       [0.14959489],\n",
              "       [0.5235635 ],\n",
              "       [0.21565402]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60golPOEvppj",
        "colab_type": "text"
      },
      "source": [
        "A value close to 0.0 means a negative sentiment and a value close to 1.0 means a positive sentiment. These numbers will vary every time you train the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H383ReVNyIec",
        "colab_type": "text"
      },
      "source": [
        "TWITTER CALLS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrFjYPt9yLf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import tweepy\n",
        "\n",
        "consumer_key= ''\n",
        "consumer_secret = ''\n",
        "\n",
        "access_token = ''\n",
        "access_token_secret = ''\n",
        "\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "\n",
        "api = tweepy.API(auth)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvWKHH9RyMFJ",
        "colab_type": "code",
        "outputId": "5afdd685-b48e-4438-a1f2-cf95ad6d66b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Enter the hastag term')\n",
        "searchTerm = input()\n",
        "numb = 10\n",
        "tweetssss =tweepy.Cursor(api.search,q = searchTerm).items(numb)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the hastag term\n",
            "trump\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HVmImf9yla_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "listTweet = []\n",
        "for val in tweetssss:\n",
        "  # list.append(str(val.text))\n",
        "  print(str(val.text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9X3Dhv-y2ij",
        "colab_type": "code",
        "outputId": "a8b35a7f-e613-4450-fa2d-252ca4b5c1ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokens = tokenizer.texts_to_sequences(listTweet)\n",
        "tokens_pad = pad_sequences(tokens, maxlen=max_tokens,\n",
        "                           padding=pad, truncating=pad)\n",
        "tokens_pad.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 544)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8cpr_5E065i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.predict(tokens_pad)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
